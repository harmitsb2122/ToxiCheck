# ToxiCheck
### A Tool to Detect Cyberbullying and Check the Toxicity of Comments on Various Websites
## About
ToxiCheck is a Google Chrome Extension which primarily targets software developer websites such as Github , detects cyberbullying on them, and provides toxicity reports on comments. Along with this , Toxicheck also assists the user in avoiding the use of toxic language by suggesting gentler alternatives as they type.

[Demo Video](https://drive.google.com/file/d/1AHUO4LCQu2TPE0iGI-8iwmO2IL37kES1/view?usp=sharing)

## Flow Diagrams
Working of the Bullying Classifier (Text Blurring Mechanism)

<img src="https://github.com/harmitsb2122/ToxiCheck/assets/80470843/cecd305b-369e-4da2-90ec-3772ef95f971" height="500px" width = "800px"></img>

Working of the Autosuggestor (Suggestion Mechanism)

<img src="https://github.com/harmitsb2122/ToxiCheck/assets/80470843/c7c28493-8c3d-412f-b15c-40b9c9ad46a6" height="500px" width = "800px"></img>

## Major Features

### Toxicity Chart

<img src="https://user-images.githubusercontent.com/80470843/235318719-f7dc54db-7e00-4299-84f6-009baf142f49.gif" height="500px" width = "800px"></img>

### Autosuggestor feature

<img src="https://user-images.githubusercontent.com/80470843/235319414-18d4ea10-7bc9-49c4-afd2-dedfb30ee764.gif" height="500px" width = "800px"></img>

## Features for Github

### Toxicity charts for Github

![Screenshot 2023-04-30 011019](https://user-images.githubusercontent.com/80470843/235321248-55b7b9c5-df7a-47a7-9fc5-f82a52de2efb.png)

### The Autosuggestor for Github

<img src="https://user-images.githubusercontent.com/80470843/235321099-488ea1d0-5733-49ba-8797-696838492b6e.png"></img>

## Instructions
1. Clone the repository
2. Enter the directory Toxicheck and type 
```
$ npm install
```
3. Go to chrome browser and type 
```
chrome://extensions/
```
4. Click on Load Unpacked option and browse to the folder Toxicheck and select it.
5. Enable/Reload the extension
6. Navigate to the websites you wish
